{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "limiting-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-conference",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "deluxe-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(path):\n",
    "    f = open(path)\n",
    "    json_content = json.load(f)\n",
    "    f.close()\n",
    "    return json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "boring-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_directory = 'datasets/rumoureval-2019-training-data/twitter-english'\n",
    "test_dataset_directory = 'datasets/rumoureval-2019-test-data/twitter-en-test-data'\n",
    "\n",
    "training_dataset_reddit_directory = 'datasets/rumoureval-2019-training-data/reddit-training-data'\n",
    "test_dataset_reddit_directory = 'datasets/rumoureval-2019-test-data/reddit-test-data'\n",
    "\n",
    "training_labels_json = 'datasets/rumoureval-2019-training-data/train-key.json'\n",
    "training_labels_json_2 = 'datasets/rumoureval-2019-training-data/dev-key.json'\n",
    "test_labels_json = 'datasets/final-eval-key.json'\n",
    "\n",
    "training_labels_dict = read_json_file(training_labels_json)['subtaskaenglish']\n",
    "training_labels_dict.update(read_json_file(training_labels_json_2)['subtaskaenglish'])\n",
    "test_labels_dict = read_json_file(test_labels_json)['subtaskaenglish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "basic-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, post_content, post_id, parent_post_id=None, external_urls_count=0):\n",
    "        self.post_content = post_content\n",
    "        self.post_id = post_id\n",
    "        self.category = None\n",
    "        self.parent_post_id = parent_post_id\n",
    "        self.external_urls = external_urls_count > 0\n",
    "        self.user_metadata = None\n",
    "        \n",
    "    def add_category(self, category):\n",
    "        self.category = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "changed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceTweet:\n",
    "    def __init__(self, tweet: Tweet):\n",
    "        self.tweet = tweet\n",
    "        self.replies = []\n",
    "        \n",
    "    def add_reply(self, reply: Tweet):\n",
    "        self.replies.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "covered-aggregate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_tweets_dataset(dataset_dir_path, labels_dict):\n",
    "    topic_directories = [f.path for f in os.scandir(dataset_dir_path) if f.is_dir()]\n",
    "    topic_to_tweets_map = {}  # {topic_name: [SourceTweet, ...]}\n",
    "\n",
    "    for topic_dir in topic_directories:\n",
    "        topic_name = topic_dir.split('\\\\')[1]\n",
    "        source_tweets = []\n",
    "        \n",
    "        tweets_paths = [f.path for f in os.scandir(topic_dir) if f.is_dir()]\n",
    "        for tweet_dir in tweets_paths:\n",
    "            source_tweet_path = [f.path for f in os.scandir(tweet_dir + '/source-tweet')][0]\n",
    "            source_tweet_json = read_json_file(source_tweet_path)\n",
    "            \n",
    "            tweet = Tweet(source_tweet_json['text'], source_tweet_json['id'],\n",
    "                              source_tweet_json['in_reply_to_status_id'],\n",
    "                              len(source_tweet_json['entities']['urls']))\n",
    "            \n",
    "            source_tweet = SourceTweet(tweet)\n",
    "            source_tweets.append(source_tweet)\n",
    "            tweet.add_category(\"support\")\n",
    "            source_tweet.add_reply(tweet)\n",
    "\n",
    "            \n",
    "            reply_tweets_paths = [f.path for f in os.scandir(tweet_dir + '/replies')]\n",
    "            for reply_tweet_path in reply_tweets_paths:\n",
    "                reply_tweet_json = read_json_file(reply_tweet_path)\n",
    "                \n",
    "                reply_tweet = Tweet(reply_tweet_json['text'], reply_tweet_json['id'],\n",
    "                                        source_tweet.tweet.post_id, len(reply_tweet_json['entities']['urls']))\n",
    "                reply_tweet.add_category(labels_dict[str(reply_tweet_json['id'])])\n",
    "                source_tweet.add_reply(reply_tweet)\n",
    "        \n",
    "        topic_to_tweets_map[topic_name] = source_tweets\n",
    "        \n",
    "    return topic_to_tweets_map\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "individual-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddit_dataset(dataset_dir_path, labels_dict):\n",
    "    topic_directories = [f.path for f in os.scandir(dataset_dir_path) if f.is_dir()]\n",
    "    topic_to_tweets_map = {}  # {topic_name: [SourceTweet, ...]}\n",
    "\n",
    "    for topic_dir in topic_directories:\n",
    "        topic_name = topic_dir.split('\\\\')[1]\n",
    "        source_tweets = []\n",
    "        \n",
    "        source_tweet_path = [f.path for f in os.scandir(topic_dir + '/source-tweet')][0]\n",
    "        source_tweet_json = read_json_file(source_tweet_path)\n",
    "\n",
    "        content = source_tweet_json['data']['children'][0]['data']['title'] + ' ' + source_tweet_json['data']['children'][0]['data']['selftext']\n",
    "        tweet = Tweet(content, source_tweet_json['data']['children'][0]['data']['id'], None, content.count(\"http\"))\n",
    "\n",
    "        source_tweet = SourceTweet(tweet)\n",
    "        source_tweets.append(source_tweet)\n",
    "        tweet.add_category(\"support\")\n",
    "        source_tweet.add_reply(tweet)\n",
    "\n",
    "        reply_tweets_paths = [f.path for f in os.scandir(topic_dir + '/replies')]\n",
    "        for reply_tweet_path in reply_tweets_paths:\n",
    "            reply_tweet_json = read_json_file(reply_tweet_path)\n",
    "            \n",
    "            if 'body' in reply_tweet_json['data']:\n",
    "                reply_tweet = Tweet(reply_tweet_json['data']['body'], reply_tweet_json['data']['id'],\n",
    "                                        source_tweet.tweet.post_id, reply_tweet_json['data']['body'].count('http'))\n",
    "                reply_tweet.add_category(labels_dict[str(reply_tweet.post_id)])\n",
    "                source_tweet.add_reply(reply_tweet)\n",
    "                \n",
    "        topic_to_tweets_map[topic_name] = source_tweets\n",
    "        \n",
    "    return topic_to_tweets_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "driven-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "training_topic_to_tweets_map = read_tweets_dataset(training_dataset_directory, training_labels_dict)\n",
    "test_topic_to_tweets_map = read_tweets_dataset(test_dataset_directory, test_labels_dict)\n",
    "\n",
    "# Reddit\n",
    "training_topic_to_reddit_map = read_reddit_dataset(training_dataset_reddit_directory, training_labels_dict)\n",
    "test_topic_to_reddit_map = read_reddit_dataset(test_dataset_reddit_directory, test_labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-ethnic",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "every-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "small-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    lemmatizer = nlp.get_pipe(\"lemmatizer\")        \n",
    "    doc = nlp(sentence)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        elif token.pos_ == \"NUM\":\n",
    "            lemmas.append('#')\n",
    "        elif token.pos_ == \"SYM\":\n",
    "            continue\n",
    "        else:\n",
    "            lemmas.append(token.lemma_.lower())\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "agricultural-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(topic_map):\n",
    "    rows = []\n",
    "    for topic, source_tweets in topic_map.items():\n",
    "        for source_tweet in source_tweets:\n",
    "            tokenized_source_tweet = preprocessing(source_tweet.tweet.post_content)\n",
    "            for reply in source_tweet.replies:\n",
    "                tokenized_reply = preprocessing(reply.post_content)\n",
    "                rows.append((topic, source_tweet.tweet.post_content, reply.post_content, tokenized_source_tweet, tokenized_reply, reply.external_urls, reply.category))\n",
    "    return pd.DataFrame(rows, columns=['topic', 'original_source_tweet', 'original_reply', 'source_tweet', 'reply', 'external_urls', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-brown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "chemical-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_df = create_df(training_topic_to_tweets_map)\n",
    "test_tweets_df = create_df(test_topic_to_tweets_map)\n",
    "training_reddit_df = create_df(training_topic_to_reddit_map)\n",
    "test_reddit_df = create_df(test_topic_to_reddit_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "upset-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>original_source_tweet</th>\n",
       "      <th>original_reply</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>MT @euronews France: 10 dead after shooting at...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>[mt, @euronews, france, :, #, dead, shoot, hq,...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@j0nathandavis They who? Stupid and partial op...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>[@j0nathandavis, ?, stupid, partial, opinion, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@nanoSpawn Socialists, Antisemites, anti zioni...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>[@nanospawn, socialists, ,, antisemites, ,, an...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@euronews @TradeDesk_Steve A French crime of p...</td>\n",
       "      <td>[france, :, #, people, dead, shoot, hq, satiri...</td>\n",
       "      <td>[@euronews, @tradedesk_steve, french, crime, p...</td>\n",
       "      <td>False</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL The 6 of us are watching this unfold...</td>\n",
       "      <td>[police, confirm, #, sydneysiege, finally, ., ...</td>\n",
       "      <td>[@angus_ol, #, watch, unfold, ,, shake, ,, hea...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@emaccaz_ omfg it is 😱😱😱😱😱</td>\n",
       "      <td>[police, confirm, #, sydneysiege, finally, ., ...</td>\n",
       "      <td>[@emaccaz, _, omfg, 😱, 😱, 😱, 😱, 😱]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL thank god they're all safe now. some...</td>\n",
       "      <td>[police, confirm, #, sydneysiege, finally, ., ...</td>\n",
       "      <td>[@angus_ol, thank, god, safe, ., wound, ,, saf...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL thank god its over, they're finally ...</td>\n",
       "      <td>[police, confirm, #, sydneysiege, finally, ., ...</td>\n",
       "      <td>[@angus_ol, thank, god, ,, finally, safe, ,, w...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL :(</td>\n",
       "      <td>[police, confirm, #, sydneysiege, finally, ., ...</td>\n",
       "      <td>[@angus_ol, :(]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                              original_source_tweet  \\\n",
       "0     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "1     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "2     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "3     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "4     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "...            ...                                                ...   \n",
       "5563   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5564   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5565   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5566   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5567   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "\n",
       "                                         original_reply  \\\n",
       "0     France: 10 people dead after shooting at HQ of...   \n",
       "1     MT @euronews France: 10 dead after shooting at...   \n",
       "2     @j0nathandavis They who? Stupid and partial op...   \n",
       "3     @nanoSpawn Socialists, Antisemites, anti zioni...   \n",
       "4     @euronews @TradeDesk_Steve A French crime of p...   \n",
       "...                                                 ...   \n",
       "5563  @Angus_OL The 6 of us are watching this unfold...   \n",
       "5564                         @emaccaz_ omfg it is 😱😱😱😱😱   \n",
       "5565  @Angus_OL thank god they're all safe now. some...   \n",
       "5566  @Angus_OL thank god its over, they're finally ...   \n",
       "5567                                       @Angus_OL :(   \n",
       "\n",
       "                                           source_tweet  \\\n",
       "0     [france, :, #, people, dead, shoot, hq, satiri...   \n",
       "1     [france, :, #, people, dead, shoot, hq, satiri...   \n",
       "2     [france, :, #, people, dead, shoot, hq, satiri...   \n",
       "3     [france, :, #, people, dead, shoot, hq, satiri...   \n",
       "4     [france, :, #, people, dead, shoot, hq, satiri...   \n",
       "...                                                 ...   \n",
       "5563  [police, confirm, #, sydneysiege, finally, ., ...   \n",
       "5564  [police, confirm, #, sydneysiege, finally, ., ...   \n",
       "5565  [police, confirm, #, sydneysiege, finally, ., ...   \n",
       "5566  [police, confirm, #, sydneysiege, finally, ., ...   \n",
       "5567  [police, confirm, #, sydneysiege, finally, ., ...   \n",
       "\n",
       "                                                  reply  external_urls  \\\n",
       "0     [france, :, #, people, dead, shoot, hq, satiri...          False   \n",
       "1     [mt, @euronews, france, :, #, dead, shoot, hq,...          False   \n",
       "2     [@j0nathandavis, ?, stupid, partial, opinion, ...          False   \n",
       "3     [@nanospawn, socialists, ,, antisemites, ,, an...          False   \n",
       "4     [@euronews, @tradedesk_steve, french, crime, p...          False   \n",
       "...                                                 ...            ...   \n",
       "5563  [@angus_ol, #, watch, unfold, ,, shake, ,, hea...          False   \n",
       "5564                 [@emaccaz, _, omfg, 😱, 😱, 😱, 😱, 😱]          False   \n",
       "5565  [@angus_ol, thank, god, safe, ., wound, ,, saf...          False   \n",
       "5566  [@angus_ol, thank, god, ,, finally, safe, ,, w...          False   \n",
       "5567                                    [@angus_ol, :(]          False   \n",
       "\n",
       "     category  \n",
       "0     support  \n",
       "1     comment  \n",
       "2        deny  \n",
       "3     comment  \n",
       "4       query  \n",
       "...       ...  \n",
       "5563  support  \n",
       "5564  comment  \n",
       "5565  support  \n",
       "5566  comment  \n",
       "5567  comment  \n",
       "\n",
       "[5568 rows x 7 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "studied-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>original_source_tweet</th>\n",
       "      <th>original_reply</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>@TODAYshow \\n\\nBig expensive payload to kill 3...</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>[@todayshow, \\n\\n, big, expensive, payload, ki...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>@TODAYshow How many ISIS did it kill?</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>[@todayshow, isis, kill, ?]</td>\n",
       "      <td>False</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>@TODAYshow @HallieJackson The mother... give m...</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>[@todayshow, @halliejackson, mother, ..., beak...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the “mot...</td>\n",
       "      <td>@TODAYshow \\nBefore and after, looks like ther...</td>\n",
       "      <td>[#, break, :, pentagon, release, video, \", mot...</td>\n",
       "      <td>[@todayshow, \\n, ,, look, like, ., wipe, lands...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>From @clairezillman:\\n\\n\"Those fires took plac...</td>\n",
       "      <td>[@jimpuzzanghera, :, \\n\\n, \", house, republica...</td>\n",
       "      <td>[@clairezillman, :, \\n\\n, \", fire, take, place...</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>And @SteveKnight25, your \"YEA\" vote in favor o...</td>\n",
       "      <td>[@jimpuzzanghera, :, \\n\\n, \", house, republica...</td>\n",
       "      <td>[@steveknight25, ,, \", yea, \", vote, favor, pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>@CA25UP @SteveKnight25 DAAAAAAMN. You got ownn...</td>\n",
       "      <td>[@jimpuzzanghera, :, \\n\\n, \", house, republica...</td>\n",
       "      <td>[@ca25up, @steveknight25, daaaaaamn, ., got, o...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>Btw, a one-time disaster relief package does n...</td>\n",
       "      <td>[@jimpuzzanghera, :, \\n\\n, \", house, republica...</td>\n",
       "      <td>[btw, ,, -, time, disaster, relief, package, u...</td>\n",
       "      <td>True</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>@CA25UP @SteveKnight25 @JoyAnnReid You’re outt...</td>\n",
       "      <td>[@jimpuzzanghera, :, \\n\\n, \", house, republica...</td>\n",
       "      <td>[@ca25up, @steveknight25, @joyannreid, outta, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    topic                              original_source_tweet  \\\n",
       "0             afghanistan  #Breaking: Pentagon releases video of the “mot...   \n",
       "1             afghanistan  #Breaking: Pentagon releases video of the “mot...   \n",
       "2             afghanistan  #Breaking: Pentagon releases video of the “mot...   \n",
       "3             afghanistan  #Breaking: Pentagon releases video of the “mot...   \n",
       "4             afghanistan  #Breaking: Pentagon releases video of the “mot...   \n",
       "...                   ...                                                ...   \n",
       "1061  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1062  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1063  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1064  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1065  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "\n",
       "                                         original_reply  \\\n",
       "0     #Breaking: Pentagon releases video of the “mot...   \n",
       "1     @TODAYshow \\n\\nBig expensive payload to kill 3...   \n",
       "2                 @TODAYshow How many ISIS did it kill?   \n",
       "3     @TODAYshow @HallieJackson The mother... give m...   \n",
       "4     @TODAYshow \\nBefore and after, looks like ther...   \n",
       "...                                                 ...   \n",
       "1061  From @clairezillman:\\n\\n\"Those fires took plac...   \n",
       "1062  And @SteveKnight25, your \"YEA\" vote in favor o...   \n",
       "1063  @CA25UP @SteveKnight25 DAAAAAAMN. You got ownn...   \n",
       "1064  Btw, a one-time disaster relief package does n...   \n",
       "1065  @CA25UP @SteveKnight25 @JoyAnnReid You’re outt...   \n",
       "\n",
       "                                           source_tweet  \\\n",
       "0     [#, break, :, pentagon, release, video, \", mot...   \n",
       "1     [#, break, :, pentagon, release, video, \", mot...   \n",
       "2     [#, break, :, pentagon, release, video, \", mot...   \n",
       "3     [#, break, :, pentagon, release, video, \", mot...   \n",
       "4     [#, break, :, pentagon, release, video, \", mot...   \n",
       "...                                                 ...   \n",
       "1061  [@jimpuzzanghera, :, \\n\\n, \", house, republica...   \n",
       "1062  [@jimpuzzanghera, :, \\n\\n, \", house, republica...   \n",
       "1063  [@jimpuzzanghera, :, \\n\\n, \", house, republica...   \n",
       "1064  [@jimpuzzanghera, :, \\n\\n, \", house, republica...   \n",
       "1065  [@jimpuzzanghera, :, \\n\\n, \", house, republica...   \n",
       "\n",
       "                                                  reply  external_urls  \\\n",
       "0     [#, break, :, pentagon, release, video, \", mot...          False   \n",
       "1     [@todayshow, \\n\\n, big, expensive, payload, ki...          False   \n",
       "2                           [@todayshow, isis, kill, ?]          False   \n",
       "3     [@todayshow, @halliejackson, mother, ..., beak...          False   \n",
       "4     [@todayshow, \\n, ,, look, like, ., wipe, lands...          False   \n",
       "...                                                 ...            ...   \n",
       "1061  [@clairezillman, :, \\n\\n, \", fire, take, place...           True   \n",
       "1062  [@steveknight25, ,, \", yea, \", vote, favor, pa...          False   \n",
       "1063  [@ca25up, @steveknight25, daaaaaamn, ., got, o...          False   \n",
       "1064  [btw, ,, -, time, disaster, relief, package, u...           True   \n",
       "1065  [@ca25up, @steveknight25, @joyannreid, outta, ...          False   \n",
       "\n",
       "     category  \n",
       "0     support  \n",
       "1     comment  \n",
       "2       query  \n",
       "3     comment  \n",
       "4     comment  \n",
       "...       ...  \n",
       "1061  support  \n",
       "1062  comment  \n",
       "1063  comment  \n",
       "1064  comment  \n",
       "1065  comment  \n",
       "\n",
       "[1066 rows x 7 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "macro-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>original_source_tweet</th>\n",
       "      <th>original_reply</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18dmb4</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18dmb4</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>Wikipedia would be a good start, I think.  \\nh...</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>[wikipedia, good, start, ,, think, .,  \\n, htt...</td>\n",
       "      <td>True</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18dmb4</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>Snopes has the basics:  \\nwww.snopes.com/humor...</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>[snope, basic, :,  \\n, www.snopes.com/humor/if...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18dmb4</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>Just about every sentence is wrong, as others ...</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>[sentence, wrong, ,, point, ,, puzzle, go, aut...</td>\n",
       "      <td>True</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18dmb4</td>\n",
       "      <td>Even ants won't eat aspartame!</td>\n",
       "      <td>I find the Snopes ant test fascinating but it ...</td>\n",
       "      <td>[ant, will, eat, aspartame, !]</td>\n",
       "      <td>[find, snopes, ant, test, fascinating, bring, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>8yktu5</td>\n",
       "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
       "      <td>Quote:\\n\\n&amp;gt; I was opening Turnberry the day...</td>\n",
       "      <td>[jon, sopel, :, bizarre, ., @realdonaldtrump, ...</td>\n",
       "      <td>[quote, :, \\n\\n, &amp;, gt, ;, open, turnberry, da...</td>\n",
       "      <td>False</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>8yktu5</td>\n",
       "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[jon, sopel, :, bizarre, ., @realdonaldtrump, ...</td>\n",
       "      <td>[[, delete, ]]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>8yktu5</td>\n",
       "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
       "      <td>He said he was opening it the day before Brexi...</td>\n",
       "      <td>[jon, sopel, :, bizarre, ., @realdonaldtrump, ...</td>\n",
       "      <td>[say, open, day, brexit, ., \\n\\n, charitable, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>8yktu5</td>\n",
       "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
       "      <td>\"Well if you remember I was opening Turnberry ...</td>\n",
       "      <td>[jon, sopel, :, bizarre, ., @realdonaldtrump, ...</td>\n",
       "      <td>[\", remember, open, turnberry, day, brexit, \",...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>8yktu5</td>\n",
       "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
       "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
       "      <td>[jon, sopel, :, bizarre, ., @realdonaldtrump, ...</td>\n",
       "      <td>[yeah, like, blatantly, lie, remember, ,, bad, ?]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                              original_source_tweet  \\\n",
       "0    18dmb4                    Even ants won't eat aspartame!    \n",
       "1    18dmb4                    Even ants won't eat aspartame!    \n",
       "2    18dmb4                    Even ants won't eat aspartame!    \n",
       "3    18dmb4                    Even ants won't eat aspartame!    \n",
       "4    18dmb4                    Even ants won't eat aspartame!    \n",
       "..      ...                                                ...   \n",
       "681  8yktu5  Jon Sopel: Bizarre. @realDonaldTrump says he c...   \n",
       "682  8yktu5  Jon Sopel: Bizarre. @realDonaldTrump says he c...   \n",
       "683  8yktu5  Jon Sopel: Bizarre. @realDonaldTrump says he c...   \n",
       "684  8yktu5  Jon Sopel: Bizarre. @realDonaldTrump says he c...   \n",
       "685  8yktu5  Jon Sopel: Bizarre. @realDonaldTrump says he c...   \n",
       "\n",
       "                                        original_reply  \\\n",
       "0                      Even ants won't eat aspartame!    \n",
       "1    Wikipedia would be a good start, I think.  \\nh...   \n",
       "2    Snopes has the basics:  \\nwww.snopes.com/humor...   \n",
       "3    Just about every sentence is wrong, as others ...   \n",
       "4    I find the Snopes ant test fascinating but it ...   \n",
       "..                                                 ...   \n",
       "681  Quote:\\n\\n&gt; I was opening Turnberry the day...   \n",
       "682                                          [deleted]   \n",
       "683  He said he was opening it the day before Brexi...   \n",
       "684  \"Well if you remember I was opening Turnberry ...   \n",
       "685  Yeah seems like he is either blatantly lying o...   \n",
       "\n",
       "                                          source_tweet  \\\n",
       "0                       [ant, will, eat, aspartame, !]   \n",
       "1                       [ant, will, eat, aspartame, !]   \n",
       "2                       [ant, will, eat, aspartame, !]   \n",
       "3                       [ant, will, eat, aspartame, !]   \n",
       "4                       [ant, will, eat, aspartame, !]   \n",
       "..                                                 ...   \n",
       "681  [jon, sopel, :, bizarre, ., @realdonaldtrump, ...   \n",
       "682  [jon, sopel, :, bizarre, ., @realdonaldtrump, ...   \n",
       "683  [jon, sopel, :, bizarre, ., @realdonaldtrump, ...   \n",
       "684  [jon, sopel, :, bizarre, ., @realdonaldtrump, ...   \n",
       "685  [jon, sopel, :, bizarre, ., @realdonaldtrump, ...   \n",
       "\n",
       "                                                 reply  external_urls category  \n",
       "0                       [ant, will, eat, aspartame, !]          False  support  \n",
       "1    [wikipedia, good, start, ,, think, .,  \\n, htt...           True  comment  \n",
       "2    [snope, basic, :,  \\n, www.snopes.com/humor/if...          False  comment  \n",
       "3    [sentence, wrong, ,, point, ,, puzzle, go, aut...           True  comment  \n",
       "4    [find, snopes, ant, test, fascinating, bring, ...          False  comment  \n",
       "..                                                 ...            ...      ...  \n",
       "681  [quote, :, \\n\\n, &, gt, ;, open, turnberry, da...          False     deny  \n",
       "682                                     [[, delete, ]]          False  comment  \n",
       "683  [say, open, day, brexit, ., \\n\\n, charitable, ...          False  comment  \n",
       "684  [\", remember, open, turnberry, day, brexit, \",...          False  comment  \n",
       "685  [yeah, like, blatantly, lie, remember, ,, bad, ?]          False  comment  \n",
       "\n",
       "[686 rows x 7 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dedicated-chapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>original_source_tweet</th>\n",
       "      <th>original_reply</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d7lzf</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d7lzf</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>You can't reason someone out of a belief they ...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>[reason, belief, use, reason, place, .]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d7lzf</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>From wikipedia: \"Though past research showed n...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>[wikipedia, :, \", past, research, show, correl...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1d7lzf</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>Whats the reason behind your reasoning? I reas...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>[s, reason, reasoning, ?, reason, reason, peop...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1d7lzf</td>\n",
       "      <td>Debunk This: A friend of mine claims Red Dye c...</td>\n",
       "      <td>You didn't use reason to come to the conclusio...</td>\n",
       "      <td>[debunk, :, friend, claim, red, dye, cause, ad...</td>\n",
       "      <td>[use, reason, come, conclusion, person, reason...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>xn2bn</td>\n",
       "      <td>I've been searching, and can't find a single c...</td>\n",
       "      <td>Lawl. I'm assuming you're a troll. But if not,...</td>\n",
       "      <td>[search, ,, find, single, credible, source, .,...</td>\n",
       "      <td>[lawl, ., assume, troll, ., ,, vote, office, i...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>xn2bn</td>\n",
       "      <td>I've been searching, and can't find a single c...</td>\n",
       "      <td>not saying bush was the best, or palin was the...</td>\n",
       "      <td>[search, ,, find, single, credible, source, .,...</td>\n",
       "      <td>[say, bush, good, ,, palin, good, ,, say, pret...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>xn2bn</td>\n",
       "      <td>I've been searching, and can't find a single c...</td>\n",
       "      <td>^^^^^\\nthey would do that if someone hadn't se...</td>\n",
       "      <td>[search, ,, find, single, credible, source, .,...</td>\n",
       "      <td>[^^^^^, \\n, seal, record, college]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>xn2bn</td>\n",
       "      <td>I've been searching, and can't find a single c...</td>\n",
       "      <td>You are right about that, but we didn't know s...</td>\n",
       "      <td>[search, ,, find, single, credible, source, .,...</td>\n",
       "      <td>[right, ,, know, shit, palin, ,, present, ,, c...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>xn2bn</td>\n",
       "      <td>I've been searching, and can't find a single c...</td>\n",
       "      <td>We...agree?? nice. reddit ftw</td>\n",
       "      <td>[search, ,, find, single, credible, source, .,...</td>\n",
       "      <td>[..., agree, ?, ?, nice, ., reddit, ftw]</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                              original_source_tweet  \\\n",
       "0    1d7lzf  Debunk This: A friend of mine claims Red Dye c...   \n",
       "1    1d7lzf  Debunk This: A friend of mine claims Red Dye c...   \n",
       "2    1d7lzf  Debunk This: A friend of mine claims Red Dye c...   \n",
       "3    1d7lzf  Debunk This: A friend of mine claims Red Dye c...   \n",
       "4    1d7lzf  Debunk This: A friend of mine claims Red Dye c...   \n",
       "..      ...                                                ...   \n",
       "685   xn2bn  I've been searching, and can't find a single c...   \n",
       "686   xn2bn  I've been searching, and can't find a single c...   \n",
       "687   xn2bn  I've been searching, and can't find a single c...   \n",
       "688   xn2bn  I've been searching, and can't find a single c...   \n",
       "689   xn2bn  I've been searching, and can't find a single c...   \n",
       "\n",
       "                                        original_reply  \\\n",
       "0    Debunk This: A friend of mine claims Red Dye c...   \n",
       "1    You can't reason someone out of a belief they ...   \n",
       "2    From wikipedia: \"Though past research showed n...   \n",
       "3    Whats the reason behind your reasoning? I reas...   \n",
       "4    You didn't use reason to come to the conclusio...   \n",
       "..                                                 ...   \n",
       "685  Lawl. I'm assuming you're a troll. But if not,...   \n",
       "686  not saying bush was the best, or palin was the...   \n",
       "687  ^^^^^\\nthey would do that if someone hadn't se...   \n",
       "688  You are right about that, but we didn't know s...   \n",
       "689                      We...agree?? nice. reddit ftw   \n",
       "\n",
       "                                          source_tweet  \\\n",
       "0    [debunk, :, friend, claim, red, dye, cause, ad...   \n",
       "1    [debunk, :, friend, claim, red, dye, cause, ad...   \n",
       "2    [debunk, :, friend, claim, red, dye, cause, ad...   \n",
       "3    [debunk, :, friend, claim, red, dye, cause, ad...   \n",
       "4    [debunk, :, friend, claim, red, dye, cause, ad...   \n",
       "..                                                 ...   \n",
       "685  [search, ,, find, single, credible, source, .,...   \n",
       "686  [search, ,, find, single, credible, source, .,...   \n",
       "687  [search, ,, find, single, credible, source, .,...   \n",
       "688  [search, ,, find, single, credible, source, .,...   \n",
       "689  [search, ,, find, single, credible, source, .,...   \n",
       "\n",
       "                                                 reply  external_urls category  \n",
       "0    [debunk, :, friend, claim, red, dye, cause, ad...          False  support  \n",
       "1              [reason, belief, use, reason, place, .]          False  comment  \n",
       "2    [wikipedia, :, \", past, research, show, correl...          False  comment  \n",
       "3    [s, reason, reasoning, ?, reason, reason, peop...          False  comment  \n",
       "4    [use, reason, come, conclusion, person, reason...          False  comment  \n",
       "..                                                 ...            ...      ...  \n",
       "685  [lawl, ., assume, troll, ., ,, vote, office, i...          False  comment  \n",
       "686  [say, bush, good, ,, palin, good, ,, say, pret...          False  comment  \n",
       "687                 [^^^^^, \\n, seal, record, college]          False  comment  \n",
       "688  [right, ,, know, shit, palin, ,, present, ,, c...          False  comment  \n",
       "689           [..., agree, ?, ?, nice, ., reddit, ftw]          False  comment  \n",
       "\n",
       "[690 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reddit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
