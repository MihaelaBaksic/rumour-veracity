{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "limiting-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "deluxe-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(path):\n",
    "    f = open(path)\n",
    "    json_content = json.load(f)\n",
    "    f.close()\n",
    "    return json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "boring-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_directory = 'datasets/rumoureval-2019-training-data/twitter-english'\n",
    "test_dataset_directory = 'datasets/rumoureval-2019-test-data/twitter-en-test-data'\n",
    "\n",
    "training_labels_json = 'datasets/rumoureval-2019-training-data/train-key.json'\n",
    "training_labels_json_2 = 'datasets/rumoureval-2019-training-data/dev-key.json'\n",
    "test_labels_json = 'datasets/final-eval-key.json'\n",
    "\n",
    "training_labels_dict = read_json_file(training_labels_json)['subtaskaenglish']\n",
    "training_labels_dict.update(read_json_file(training_labels_json_2)['subtaskaenglish'])\n",
    "test_labels_dict = read_json_file(test_labels_json)['subtaskaenglish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "basic-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, post_content, post_id, parent_post_id=None, external_urls_count=0):\n",
    "        self.post_content = post_content\n",
    "        self.post_id = post_id\n",
    "        self.category = None\n",
    "        self.parent_post_id = parent_post_id\n",
    "        self.external_urls = external_urls_count > 0\n",
    "        self.user_metadata = None\n",
    "        \n",
    "    def add_category(self, category):\n",
    "        self.category = category\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return f\"tweet {self.post_id}: {self.post_content}, category: {self.category}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "changed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceTweet:\n",
    "    def __init__(self, tweet: Tweet):\n",
    "        self.tweet = tweet\n",
    "        self.replies = []\n",
    "        \n",
    "    def add_reply(self, reply: Tweet):\n",
    "        self.replies.append(reply)\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return f\"source {self.tweet}: {len(self.replies)} replies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "covered-aggregate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_dataset(dataset_dir_path, labels_dict):\n",
    "    topic_directories = [f.path for f in os.scandir(dataset_dir_path) if f.is_dir()]\n",
    "    \n",
    "    topic_to_tweets_map = {}  # {topic_name: SourceTweet}\n",
    "    topic_to_tuples_map = {}  # {topic_name: (SourceTweet, Tweet)}\n",
    "\n",
    "    for topic_dir in topic_directories:\n",
    "        topic_name = topic_dir.split('\\\\')[1]\n",
    "        source_tweets = []\n",
    "        tweet_pairs = []\n",
    "        \n",
    "        tweets_paths = [f.path for f in os.scandir(topic_dir) if f.is_dir()]\n",
    "        for tweet_dir in tweets_paths:\n",
    "            source_tweet_path = [f.path for f in os.scandir(tweet_dir + '/source-tweet')][0]\n",
    "            source_tweet_json = read_json_file(source_tweet_path)\n",
    "\n",
    "            tweet = Tweet(source_tweet_json['text'], source_tweet_json['id'],\n",
    "                          source_tweet_json['in_reply_to_status_id'],\n",
    "                          len(source_tweet_json['entities']['urls']))\n",
    "            \n",
    "            source_tweet = SourceTweet(tweet)\n",
    "            source_tweets.append(source_tweet)\n",
    "\n",
    "            \n",
    "            reply_tweets_paths = [f.path for f in os.scandir(tweet_dir + '/replies')]\n",
    "            for reply_tweet_path in reply_tweets_paths:\n",
    "                reply_tweet_json = read_json_file(reply_tweet_path)\n",
    "                reply_tweet = Tweet(reply_tweet_json['text'], reply_tweet_json['id'],\n",
    "                                    source_tweet.tweet.post_id, len(reply_tweet_json['entities']['urls']))\n",
    "                reply_tweet.add_category(labels_dict[str(reply_tweet_json['id'])])\n",
    "                \n",
    "                source_tweet.add_reply(reply_tweet)\n",
    "                tweet_pairs.append((source_tweet, reply_tweet))\n",
    "        \n",
    "        topic_to_tweets_map[topic_name] = source_tweets\n",
    "        topic_to_tuples_map[topic_name] = tweet_pairs\n",
    "        \n",
    "#     print(topic_to_tweets_map)\n",
    "    return topic_to_tuples_map\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "driven-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_topic_to_tweets_map = read_dataset(training_dataset_directory, training_labels_dict)\n",
    "test_topic_to_tweets_map = read_dataset(test_dataset_directory, test_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "scientific-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(tuples_map):\n",
    "    triples = []\n",
    "    for topic, tweets_list in tuples_map.items():\n",
    "        for tweet_pair in tweets_list:\n",
    "            source_tweet, reply = tweet_pair\n",
    "            triples.append((topic, source_tweet.tweet.post_content, reply.post_content, reply.external_urls, reply.category))\n",
    "    return pd.DataFrame(triples, columns=['topic', 'source_tweet', 'reply', 'external_urls', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "chemical-vector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>MT @euronews France: 10 dead after shooting at...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@j0nathandavis They who? Stupid and partial op...</td>\n",
       "      <td>False</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@nanoSpawn Socialists, Antisemites, anti zioni...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@euronews @TradeDesk_Steve A French crime of p...</td>\n",
       "      <td>False</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>@euronews LOL. 5 million Muslims in France, wh...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL The 6 of us are watching this unfold...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@emaccaz_ omfg it is ðŸ˜±ðŸ˜±ðŸ˜±ðŸ˜±ðŸ˜±</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL thank god they're all safe now. some...</td>\n",
       "      <td>False</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL thank god its over, they're finally ...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>sydneysiege</td>\n",
       "      <td>Police confirm that #sydneysiege is finally ov...</td>\n",
       "      <td>@Angus_OL :(</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5243 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                       source_tweet  \\\n",
       "0     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "1     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "2     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "3     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "4     charliehebdo  France: 10 people dead after shooting at HQ of...   \n",
       "...            ...                                                ...   \n",
       "5238   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5239   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5240   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5241   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "5242   sydneysiege  Police confirm that #sydneysiege is finally ov...   \n",
       "\n",
       "                                                  reply  external_urls  \\\n",
       "0     MT @euronews France: 10 dead after shooting at...          False   \n",
       "1     @j0nathandavis They who? Stupid and partial op...          False   \n",
       "2     @nanoSpawn Socialists, Antisemites, anti zioni...          False   \n",
       "3     @euronews @TradeDesk_Steve A French crime of p...          False   \n",
       "4     @euronews LOL. 5 million Muslims in France, wh...          False   \n",
       "...                                                 ...            ...   \n",
       "5238  @Angus_OL The 6 of us are watching this unfold...          False   \n",
       "5239                         @emaccaz_ omfg it is ðŸ˜±ðŸ˜±ðŸ˜±ðŸ˜±ðŸ˜±          False   \n",
       "5240  @Angus_OL thank god they're all safe now. some...          False   \n",
       "5241  @Angus_OL thank god its over, they're finally ...          False   \n",
       "5242                                       @Angus_OL :(          False   \n",
       "\n",
       "     category  \n",
       "0     comment  \n",
       "1        deny  \n",
       "2     comment  \n",
       "3       query  \n",
       "4     comment  \n",
       "...       ...  \n",
       "5238  support  \n",
       "5239  comment  \n",
       "5240  support  \n",
       "5241  comment  \n",
       "5242  comment  \n",
       "\n",
       "[5243 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = create_df(training_topic_to_tweets_map)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "studied-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>source_tweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the â€œmot...</td>\n",
       "      <td>@TODAYshow \\n\\nBig expensive payload to kill 3...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the â€œmot...</td>\n",
       "      <td>@TODAYshow How many ISIS did it kill?</td>\n",
       "      <td>False</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the â€œmot...</td>\n",
       "      <td>@TODAYshow @HallieJackson The mother... give m...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the â€œmot...</td>\n",
       "      <td>@TODAYshow \\nBefore and after, looks like ther...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>#Breaking: Pentagon releases video of the â€œmot...</td>\n",
       "      <td>@TODAYshow The next one could be the Daddy of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>From @clairezillman:\\n\\n\"Those fires took plac...</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>And @SteveKnight25, your \"YEA\" vote in favor o...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>@CA25UP @SteveKnight25 DAAAAAAMN. You got ownn...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>Btw, a one-time disaster relief package does n...</td>\n",
       "      <td>True</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>wildfires-deduction</td>\n",
       "      <td>From @JimPuzzanghera:\\n\\n\"The House Republican...</td>\n",
       "      <td>@CA25UP @SteveKnight25 @JoyAnnReid Youâ€™re outt...</td>\n",
       "      <td>False</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    topic                                       source_tweet  \\\n",
       "0             afghanistan  #Breaking: Pentagon releases video of the â€œmot...   \n",
       "1             afghanistan  #Breaking: Pentagon releases video of the â€œmot...   \n",
       "2             afghanistan  #Breaking: Pentagon releases video of the â€œmot...   \n",
       "3             afghanistan  #Breaking: Pentagon releases video of the â€œmot...   \n",
       "4             afghanistan  #Breaking: Pentagon releases video of the â€œmot...   \n",
       "...                   ...                                                ...   \n",
       "1005  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1006  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1007  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1008  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "1009  wildfires-deduction  From @JimPuzzanghera:\\n\\n\"The House Republican...   \n",
       "\n",
       "                                                  reply  external_urls  \\\n",
       "0     @TODAYshow \\n\\nBig expensive payload to kill 3...          False   \n",
       "1                 @TODAYshow How many ISIS did it kill?          False   \n",
       "2     @TODAYshow @HallieJackson The mother... give m...          False   \n",
       "3     @TODAYshow \\nBefore and after, looks like ther...          False   \n",
       "4     @TODAYshow The next one could be the Daddy of ...          False   \n",
       "...                                                 ...            ...   \n",
       "1005  From @clairezillman:\\n\\n\"Those fires took plac...           True   \n",
       "1006  And @SteveKnight25, your \"YEA\" vote in favor o...          False   \n",
       "1007  @CA25UP @SteveKnight25 DAAAAAAMN. You got ownn...          False   \n",
       "1008  Btw, a one-time disaster relief package does n...           True   \n",
       "1009  @CA25UP @SteveKnight25 @JoyAnnReid Youâ€™re outt...          False   \n",
       "\n",
       "     category  \n",
       "0     comment  \n",
       "1       query  \n",
       "2     comment  \n",
       "3     comment  \n",
       "4     comment  \n",
       "...       ...  \n",
       "1005  support  \n",
       "1006  comment  \n",
       "1007  comment  \n",
       "1008  comment  \n",
       "1009  comment  \n",
       "\n",
       "[1010 rows x 5 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = create_df(test_topic_to_tweets_map)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-thursday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
