{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limiting-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-conference",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deluxe-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(path):\n",
    "    f = open(path)\n",
    "    json_content = json.load(f)\n",
    "    f.close()\n",
    "    return json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "boring-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_directory = 'datasets/rumoureval-2019-training-data/twitter-english'\n",
    "test_dataset_directory = 'datasets/rumoureval-2019-test-data/twitter-en-test-data'\n",
    "\n",
    "training_dataset_reddit_directory = 'datasets/rumoureval-2019-training-data/reddit-training-data'\n",
    "test_dataset_reddit_directory = 'datasets/rumoureval-2019-test-data/reddit-test-data'\n",
    "\n",
    "training_labels_json = 'datasets/rumoureval-2019-training-data/train-key.json'\n",
    "training_labels_json_2 = 'datasets/rumoureval-2019-training-data/dev-key.json'\n",
    "test_labels_json = 'datasets/final-eval-key.json'\n",
    "\n",
    "training_labels_dict = read_json_file(training_labels_json)['subtaskaenglish']\n",
    "training_labels_dict.update(read_json_file(training_labels_json_2)['subtaskaenglish'])\n",
    "test_labels_dict = read_json_file(test_labels_json)['subtaskaenglish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, post_content, post_id, parent_post_id=None, external_urls_count=0):\n",
    "        self.post_content = post_content\n",
    "        self.post_id = post_id\n",
    "        self.category = None\n",
    "        self.parent_post_id = parent_post_id\n",
    "        self.external_urls = external_urls_count > 0\n",
    "        self.user_metadata = None\n",
    "        \n",
    "    def add_category(self, category):\n",
    "        self.category = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceTweet:\n",
    "    def __init__(self, tweet: Tweet):\n",
    "        self.tweet = tweet\n",
    "        self.replies = []\n",
    "        \n",
    "    def add_reply(self, reply: Tweet):\n",
    "        self.replies.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "covered-aggregate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_tweets_dataset(dataset_dir_path, labels_dict):\n",
    "    topic_directories = [f.path for f in os.scandir(dataset_dir_path) if f.is_dir()]\n",
    "    topic_to_tweets_map = {}  # {topic_name: [SourceTweet, ...]}\n",
    "    # print(topic_directories)\n",
    "    for topic_dir in topic_directories:\n",
    "        \n",
    "        topic_name = topic_dir.split('\\\\')[1]\n",
    "        source_tweets = []\n",
    "        \n",
    "        tweets_paths = [f.path for f in os.scandir(topic_dir) if f.is_dir()]\n",
    "        for tweet_dir in tweets_paths:\n",
    "            source_tweet_path = [f.path for f in os.scandir(tweet_dir + '/source-tweet')][0]\n",
    "            source_tweet_json = read_json_file(source_tweet_path)\n",
    "            \n",
    "            tweet = Tweet(source_tweet_json['text'], source_tweet_json['id'],\n",
    "                              source_tweet_json['in_reply_to_status_id'],\n",
    "                              len(source_tweet_json['entities']['urls']))\n",
    "            \n",
    "            source_tweet = SourceTweet(tweet)\n",
    "            source_tweets.append(source_tweet)\n",
    "            tweet.add_category(\"support\")\n",
    "            source_tweet.add_reply(tweet)\n",
    "\n",
    "            \n",
    "            reply_tweets_paths = [f.path for f in os.scandir(tweet_dir + '/replies')]\n",
    "            for reply_tweet_path in reply_tweets_paths:\n",
    "                reply_tweet_json = read_json_file(reply_tweet_path)\n",
    "                \n",
    "                reply_tweet = Tweet(reply_tweet_json['text'], reply_tweet_json['id'],\n",
    "                                        source_tweet.tweet.post_id, len(reply_tweet_json['entities']['urls']))\n",
    "                reply_tweet.add_category(labels_dict[str(reply_tweet_json['id'])])\n",
    "                source_tweet.add_reply(reply_tweet)\n",
    "        \n",
    "        topic_to_tweets_map[topic_name] = source_tweets\n",
    "        \n",
    "    return topic_to_tweets_map\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "individual-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddit_dataset(dataset_dir_path, labels_dict):\n",
    "    topic_directories = [f.path for f in os.scandir(dataset_dir_path) if f.is_dir()]\n",
    "    topic_to_tweets_map = {}  # {topic_name: [SourceTweet, ...]}\n",
    "\n",
    "    for topic_dir in topic_directories:\n",
    "        topic_name = topic_dir.split('\\\\')[1]\n",
    "        source_tweets = []\n",
    "        \n",
    "        source_tweet_path = [f.path for f in os.scandir(topic_dir + '/source-tweet')][0]\n",
    "        source_tweet_json = read_json_file(source_tweet_path)\n",
    "\n",
    "        content = source_tweet_json['data']['children'][0]['data']['title'] + ' ' + source_tweet_json['data']['children'][0]['data']['selftext']\n",
    "        tweet = Tweet(content, source_tweet_json['data']['children'][0]['data']['id'], None, content.count(\"http\"))\n",
    "\n",
    "        source_tweet = SourceTweet(tweet)\n",
    "        source_tweets.append(source_tweet)\n",
    "        tweet.add_category(\"support\")\n",
    "        source_tweet.add_reply(tweet)\n",
    "\n",
    "        reply_tweets_paths = [f.path for f in os.scandir(topic_dir + '/replies')]\n",
    "        for reply_tweet_path in reply_tweets_paths:\n",
    "            reply_tweet_json = read_json_file(reply_tweet_path)\n",
    "            \n",
    "            if 'body' in reply_tweet_json['data']:\n",
    "                reply_tweet = Tweet(reply_tweet_json['data']['body'], reply_tweet_json['data']['id'],\n",
    "                                        source_tweet.tweet.post_id, reply_tweet_json['data']['body'].count('http'))\n",
    "                reply_tweet.add_category(labels_dict[str(reply_tweet.post_id)])\n",
    "                source_tweet.add_reply(reply_tweet)\n",
    "                \n",
    "        topic_to_tweets_map[topic_name] = source_tweets\n",
    "        \n",
    "    return topic_to_tweets_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "driven-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "training_topic_to_tweets_map = read_tweets_dataset(training_dataset_directory, training_labels_dict)\n",
    "test_topic_to_tweets_map = read_tweets_dataset(test_dataset_directory, test_labels_dict)\n",
    "\n",
    "# Reddit\n",
    "# training_topic_to_reddit_map = read_reddit_dataset(training_dataset_reddit_directory, training_labels_dict)\n",
    "# test_topic_to_reddit_map = read_reddit_dataset(test_dataset_reddit_directory, test_labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-ethnic",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "every-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "punctuation = string.punctuation.replace(\"!\", \"\")\n",
    "punctuation = punctuation.replace(\"?\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    lemmatizer = nlp.get_pipe(\"lemmatizer\")        \n",
    "    doc = nlp(sentence)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        elif token.pos_ == \"NUM\":\n",
    "            lemmas.append('#')\n",
    "        elif token.pos_ == \"SYM\":\n",
    "            continue\n",
    "        elif token.text in punctuation:\n",
    "            continue\n",
    "        elif re.search(r\"[http.*]\", token.text):\n",
    "            continue\n",
    "        else:\n",
    "            lemmas.append(token.lemma_.lower())\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(topic_map):\n",
    "    rows = []\n",
    "    for topic, source_tweets in topic_map.items():\n",
    "        for source_tweet in source_tweets:\n",
    "            tokenized_source_tweet = preprocessing(source_tweet.tweet.post_content)\n",
    "            for reply in source_tweet.replies:\n",
    "                tokenized_reply = preprocessing(reply.post_content)\n",
    "                rows.append((topic, source_tweet.tweet.post_content, reply.post_content, tokenized_source_tweet, tokenized_reply, reply.external_urls, reply.category))\n",
    "    return pd.DataFrame(rows, columns=['topic', 'original_source_tweet', 'original_reply', 'source_tweet', 'reply', 'external_urls', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-brown",
   "metadata": {},
   "source": [
    "## CountVectorizer and TfidfVectorizer feature extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chemical-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_df = create_df(training_topic_to_tweets_map)\n",
    "test_tweets_df = create_df(test_topic_to_tweets_map)\n",
    "# training_reddit_df = create_df(training_topic_to_reddit_map)\n",
    "# test_reddit_df = create_df(test_topic_to_reddit_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1282a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_tweets_df\n",
    "# test_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upset-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = training_tweets_df[['reply', 'category']].values\n",
    "test_data = test_tweets_df[['reply', 'category']].values\n",
    "# training_tweets_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "studied-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "label_map = {'comment':0, 'support':1, 'deny':2, 'query':3}\n",
    "\n",
    "def count_vectorize(data, ngram, count_vect=None):\n",
    "    \n",
    "\n",
    "    text_data = []\n",
    "    labels = []\n",
    "    for i in data:\n",
    "        text_data.append(' '.join(i[0]))\n",
    "        labels.append(label_map[i[1]])\n",
    "    \n",
    "    if count_vect is None:\n",
    "        count_vect = CountVectorizer(ngram_range=(ngram, ngram), token_pattern = '[a-zA-Z0-9#?!]+')\n",
    "        count_vect.fit(text_data)\n",
    "    \n",
    "    vectorized_data = count_vect.transform(text_data)\n",
    "    \n",
    "    return vectorized_data.toarray(), np.array(labels), count_vect\n",
    "    \n",
    "    # for i in text_data:\n",
    "    #     count_vect.transform()\n",
    "\n",
    "def tfidf_vectorize(data, ngram, count_vect=None):\n",
    "    \n",
    "\n",
    "    text_data = []\n",
    "    labels = []\n",
    "    for i in data:\n",
    "        text_data.append(' '.join(i[0]))\n",
    "        labels.append(label_map[i[1]])\n",
    "    \n",
    "    if count_vect is None:\n",
    "        count_vect = TfidfVectorizer(ngram_range=(ngram, ngram), token_pattern = '[a-zA-Z0-9#?!]+')\n",
    "        \n",
    "        count_vect.fit(text_data)\n",
    "        # print(count_vect.get_feature_names_out())\n",
    "    \n",
    "    vectorized_data = count_vect.transform(text_data)\n",
    "    \n",
    "    return vectorized_data.toarray(), np.array(labels), count_vect\n",
    "\n",
    "# print(training_data[:5])\n",
    "# X_train, y_train, count_vect = tfidf_vectorize(training_data[:5], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c76ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_pred, y_test, name, ngram_size = None):\n",
    "    if ngram_size is not None:\n",
    "        print(f'{name}, {ngram_size}-grams:')\n",
    "    else:\n",
    "        print(f'{name}:')\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    # print(y_pred.count(0), y_test.count(0))\n",
    "\n",
    "    \n",
    "    print(\" Classification accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\" Micro F1 score: \", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\" Macro F1 score: \", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\" Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "    target_names = ['comment', 'support', 'deny', 'query']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "629560ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5568, 14148), (5568,), (1066, 14148), (1066,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "ngram_size = 2\n",
    "\n",
    "\n",
    "X_train, y_train, count_vect = tfidf_vectorize(training_data, ngram_size)\n",
    "X_test, y_test, _ = tfidf_vectorize(test_data, ngram_size, count_vect)\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f139071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, 2-grams:\n",
      "{0: 1066}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.723264540337711\n",
      " Micro F1 score:  0.723264540337711\n",
      " Macro F1 score:  0.20985302123026675\n",
      " Confusion matrix: \n",
      " [[771   0   0   0]\n",
      " [147   0   0   0]\n",
      " [ 92   0   0   0]\n",
      " [ 56   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.72      1.00      0.84       771\n",
      "     support       0.00      0.00      0.00       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.72      1066\n",
      "   macro avg       0.18      0.25      0.21      1066\n",
      "weighted avg       0.52      0.72      0.61      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "\n",
    "results(y_pred, y_test, 'Naive Bayes', ngram_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "371b05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, 2-grams:\n",
      "{0: 1053, 3: 13}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.726078799249531\n",
      " Micro F1 score:  0.726078799249531\n",
      " Macro F1 score:  0.26794908466819223\n",
      " Confusion matrix: \n",
      " [[766   0   0   5]\n",
      " [147   0   0   0]\n",
      " [ 92   0   0   0]\n",
      " [ 48   0   0   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.73      0.99      0.84       771\n",
      "     support       0.00      0.00      0.00       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.62      0.14      0.23        56\n",
      "\n",
      "    accuracy                           0.73      1066\n",
      "   macro avg       0.34      0.28      0.27      1066\n",
      "weighted avg       0.56      0.73      0.62      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter = 1000)\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "results(y_pred, y_test, 'Logistic Regression', ngram_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c8225fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD, 2-grams:\n",
      "{0: 1026, 1: 4, 2: 5, 3: 31}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.723264540337711\n",
      " Micro F1 score:  0.723264540337711\n",
      " Macro F1 score:  0.2989980103618908\n",
      " Confusion matrix: \n",
      " [[755   2   2  12]\n",
      " [141   1   1   4]\n",
      " [ 89   1   1   1]\n",
      " [ 41   0   1  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.74      0.98      0.84       771\n",
      "     support       0.25      0.01      0.01       147\n",
      "        deny       0.20      0.01      0.02        92\n",
      "       query       0.45      0.25      0.32        56\n",
      "\n",
      "    accuracy                           0.72      1066\n",
      "   macro avg       0.41      0.31      0.30      1066\n",
      "weighted avg       0.61      0.72      0.63      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier(max_iter=1000, random_state=0)\n",
    "SGD.fit(X_train, y_train)\n",
    "y_pred = SGD.predict(X_test)\n",
    "\n",
    "results(y_pred, y_test, 'SGD', ngram_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6f19a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_SVC:\n",
      "{0: 1031, 1: 4, 2: 5, 3: 26}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.7213883677298312\n",
      " Micro F1 score:  0.7213883677298312\n",
      " Macro F1 score:  0.2911260853205429\n",
      " Confusion matrix: \n",
      " [[755   3   2  11]\n",
      " [143   1   1   2]\n",
      " [ 90   0   1   1]\n",
      " [ 43   0   1  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.73      0.98      0.84       771\n",
      "     support       0.25      0.01      0.01       147\n",
      "        deny       0.20      0.01      0.02        92\n",
      "       query       0.46      0.21      0.29        56\n",
      "\n",
      "    accuracy                           0.72      1066\n",
      "   macro avg       0.41      0.30      0.29      1066\n",
      "weighted avg       0.61      0.72      0.63      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_SVC = lin_clf = svm.LinearSVC()\n",
    "linear_SVC.fit(X_train, y_train)\n",
    "y_pred = linear_SVC.predict(X_test)\n",
    "\n",
    "results(y_pred, y_test, 'Linear_SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d65a7",
   "metadata": {},
   "source": [
    "## Hand crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71442bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-twitter-25\")\n",
    "embedding_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f98dfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('negative-words.txt', 'r')\n",
    "negative_words = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open('positive-words.txt', 'r')\n",
    "positive_words = f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c989cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectors = model.wv\n",
    "# print(len(model['it']))\n",
    "\n",
    "def feature_extraction(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    features = []\n",
    "    word_embeddings = []\n",
    "    \n",
    "    neg_count = 0\n",
    "    pos_count = 0\n",
    "    number = 0\n",
    "    for token in doc:\n",
    "        if token.text in negative_words:\n",
    "            neg_count += 1\n",
    "        elif token.text in positive_words:\n",
    "            pos_count += 1\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        if token.pos_ == \"NUM\":\n",
    "            number = 1\n",
    "        # 25 features\n",
    "        elif token.text in model:\n",
    "            # print(len(model[token.text]))\n",
    "            word_embeddings.append(model[token.text])\n",
    "            \n",
    "    if len(word_embeddings) == 0:\n",
    "        word_embeddings.append([0]*embedding_length)\n",
    "        \n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    \n",
    "    # \n",
    "    features.extend(list(np.mean(word_embeddings, axis = 0)))\n",
    "    # contains number\n",
    "    features.append(number)\n",
    "    \n",
    "    # contains ?\n",
    "    if token.text.find('?'):\n",
    "        features.append(1)\n",
    "    else:\n",
    "        features.append(0)\n",
    "    \n",
    "    # contains !\n",
    "    if token.text.find('!'):\n",
    "        features.append(1)\n",
    "    else:\n",
    "        features.append(0)\n",
    "    \n",
    "    # negative and positive word count\n",
    "    features.append(neg_count)\n",
    "    features.append(pos_count)\n",
    "    \n",
    "    # capital ratio\n",
    "    uppers = [i for i in sentence if i.isupper()]\n",
    "    capitalratio = len(uppers)/len(sentence)\n",
    "    features.append(capitalratio)\n",
    "    \n",
    "    # length of sentence\n",
    "    features.append(len(sentence))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7618ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_features(topic_map):\n",
    "    rows = []\n",
    "    for topic, source_tweets in topic_map.items():\n",
    "        for source_tweet in source_tweets:\n",
    "            tokenized_source_tweet = feature_extraction(source_tweet.tweet.post_content)\n",
    "            for reply in source_tweet.replies:\n",
    "                tokenized_reply = feature_extraction(reply.post_content)\n",
    "                rows.append((topic, source_tweet.tweet.post_content, reply.post_content, tokenized_source_tweet, tokenized_reply, reply.external_urls, reply.category))\n",
    "    return pd.DataFrame(rows, columns=['topic', 'original_source_tweet', 'original_reply', 'source_tweet', 'reply', 'external_urls', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41bb7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_df_features = create_df_features(training_topic_to_tweets_map)\n",
    "test_tweets_df_features = create_df_features(test_topic_to_tweets_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1752936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_features = training_tweets_df_features[['reply', 'category']].values\n",
    "test_data_features = test_tweets_df_features[['reply', 'category']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bf4347bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5568, 32), (1066,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad = np.array([i for i in training_data_features[:, 0]])\n",
    "y_train_pad = np.array([label_map[i] for i in training_data_features[:, 1]])\n",
    "\n",
    "X_test_pad = np.array([i for i in test_data_features[:, 0]])\n",
    "y_test_features = np.array([label_map[i] for i in test_data_features[:, 1]])\n",
    "\n",
    "X_train_pad.shape, y_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc31dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "{0: 1066}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.723264540337711\n",
      " Micro F1 score:  0.723264540337711\n",
      " Macro F1 score:  0.20985302123026675\n",
      " Confusion matrix: \n",
      " [[771   0   0   0]\n",
      " [147   0   0   0]\n",
      " [ 92   0   0   0]\n",
      " [ 56   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.72      1.00      0.84       771\n",
      "     support       0.00      0.00      0.00       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.72      1066\n",
      "   macro avg       0.18      0.25      0.21      1066\n",
      "weighted avg       0.52      0.72      0.61      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "p = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "p.fit(X_train_pad,y_train) \n",
    "\n",
    "y_pred = p.predict(X_test_pad)\n",
    "\n",
    "results(y_pred, y_test_features, 'Naive Bayes')\n",
    "# X_train_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f5d618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "{0: 1007, 1: 23, 3: 36}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.7467166979362101\n",
      " Micro F1 score:  0.74671669793621\n",
      " Macro F1 score:  0.39773920523361694\n",
      " Confusion matrix: \n",
      " [[755   7   0   9]\n",
      " [131  15   0   1]\n",
      " [ 91   1   0   0]\n",
      " [ 30   0   0  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.75      0.98      0.85       771\n",
      "     support       0.65      0.10      0.18       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.72      0.46      0.57        56\n",
      "\n",
      "    accuracy                           0.75      1066\n",
      "   macro avg       0.53      0.39      0.40      1066\n",
      "weighted avg       0.67      0.75      0.67      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_features = LogisticRegression(max_iter = 5000)\n",
    "LR_features.fit(X_train_pad, y_train)\n",
    "y_pred = LR_features.predict(X_test_pad)\n",
    "\n",
    "results(y_pred, y_test_features, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17f2c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD:\n",
      "{0: 1021, 1: 4, 3: 41}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.7345215759849906\n",
      " Micro F1 score:  0.7345215759849906\n",
      " Macro F1 score:  0.3452371364138439\n",
      " Confusion matrix: \n",
      " [[757   2   0  12]\n",
      " [144   0   0   3]\n",
      " [ 90   2   0   0]\n",
      " [ 30   0   0  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.74      0.98      0.84       771\n",
      "     support       0.00      0.00      0.00       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.63      0.46      0.54        56\n",
      "\n",
      "    accuracy                           0.73      1066\n",
      "   macro avg       0.34      0.36      0.35      1066\n",
      "weighted avg       0.57      0.73      0.64      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD_features = SGDClassifier(random_state=0)\n",
    "SGD_features.fit(X_train_pad, y_train)\n",
    "y_pred = SGD_features.predict(X_test_pad)\n",
    "\n",
    "results(y_pred, y_test_features, 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52c86272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_SVC:\n",
      "{0: 1002, 1: 16, 3: 48}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.7401500938086304\n",
      " Micro F1 score:  0.7401500938086304\n",
      " Macro F1 score:  0.3781234304244332\n",
      " Confusion matrix: \n",
      " [[750   3   0  18]\n",
      " [133  12   0   2]\n",
      " [ 90   1   0   1]\n",
      " [ 29   0   0  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.75      0.97      0.85       771\n",
      "     support       0.75      0.08      0.15       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.56      0.48      0.52        56\n",
      "\n",
      "    accuracy                           0.74      1066\n",
      "   macro avg       0.52      0.38      0.38      1066\n",
      "weighted avg       0.67      0.74      0.66      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_SVC = svm.LinearSVC(dual=False)\n",
    "linear_SVC.fit(X_train_pad, y_train)\n",
    "y_pred = linear_SVC.predict(X_test_pad)\n",
    "\n",
    "results(y_pred, y_test_features, 'Linear_SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b826ccc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b {color: black;background-color: white;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b pre{padding: 0;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-toggleable {background-color: white;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-estimator:hover {background-color: #d4ebff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-item {z-index: 1;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-parallel-item:only-child::after {width: 0;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-ceb4bbf3-5c2e-4b7b-92a0-93c7b1949e0b\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3aa0474-05a4-4e75-87a8-7a9b853a2b5a\" type=\"checkbox\" ><label for=\"c3aa0474-05a4-4e75-87a8-7a9b853a2b5a\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b9c2115e-aedb-44bf-9ad3-302ded366d1e\" type=\"checkbox\" ><label for=\"b9c2115e-aedb-44bf-9ad3-302ded366d1e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"01cd1521-fffc-41c9-bdb0-fe0ae7ba97ca\" type=\"checkbox\" ><label for=\"01cd1521-fffc-41c9-bdb0-fe0ae7ba97ca\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True)\n",
    "# grid = SVC()\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train_pad, y_train)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26f85082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "afcc4285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "{0: 1013, 1: 13, 3: 40}\n",
      "{0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Classification accuracy:  0.7335834896810507\n",
      " Micro F1 score:  0.7335834896810506\n",
      " Macro F1 score:  0.34826233183856503\n",
      " Confusion matrix: \n",
      " [[752   3   0  16]\n",
      " [136   9   0   2]\n",
      " [ 90   1   0   1]\n",
      " [ 35   0   0  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.74      0.98      0.84       771\n",
      "     support       0.69      0.06      0.11       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.53      0.38      0.44        56\n",
      "\n",
      "    accuracy                           0.73      1066\n",
      "   macro avg       0.49      0.35      0.35      1066\n",
      "weighted avg       0.66      0.73      0.65      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_pred = grid.predict(X_test_pad)\n",
    "results(grid_pred, y_test_features, 'SVC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f764e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a27efdd",
   "metadata": {},
   "source": [
    "## LSTM network for stance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Bidirectional\n",
    "import keras.preprocessing.sequence as seq\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1863ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets_df['both'] = training_tweets_df['reply'] + training_tweets_df['source_tweet']\n",
    "test_tweets_df['both'] = test_tweets_df['reply'] + test_tweets_df['source_tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20190d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = api.load(\"glove-twitter-100\")\n",
    "embedding_length_nn = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3458125",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'comment':0, 'support':1, 'deny':2, 'query':3}\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(training_tweets_df['reply'])\n",
    "train_sequences = tokenizer.texts_to_sequences(training_tweets_df['reply'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_tweets_df['reply'])\n",
    "\n",
    "X_train_reply = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=embedding_length_nn, dtype='int32')\n",
    "X_test_reply = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=embedding_length_nn, dtype='int32')\n",
    "\n",
    "\n",
    "\n",
    "y_train_reply = np.array([label_map[i] for i in training_tweets_df['category'].values])\n",
    "y_train_reply = np_utils.to_categorical(y_train)\n",
    "\n",
    "y_test_reply = np.array([label_map[i] for i in test_tweets_df['category'].values])\n",
    "y_test_reply = np_utils.to_categorical(y_test)\n",
    "\n",
    "vocab_size_reply = len(tokenizer.word_index)+1\n",
    "\n",
    "# y_train_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d9c9355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4021"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_both = Tokenizer()\n",
    "tokenizer_both.fit_on_texts(training_tweets_df['both'])\n",
    "train_sequences = tokenizer_both.texts_to_sequences(training_tweets_df['both'])\n",
    "test_sequences = tokenizer_both.texts_to_sequences(test_tweets_df['both'])\n",
    "\n",
    "X_train_both = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=embedding_length_nn, dtype='int32')\n",
    "X_test_both = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=embedding_length_nn, dtype='int32')\n",
    "\n",
    "\n",
    "vocab_size_both = len(tokenizer_both.word_index)+1\n",
    "vocab_size_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a23b2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_nn(y_pred, y_test):\n",
    "    # if ngram_size is not None:\n",
    "    #     print(f'{name}, {ngram_size}-grams:')\n",
    "    # else:\n",
    "    #     print(f'{name}:')\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    print('Pred:', dict(zip(unique, counts)))\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    print('Test:', dict(zip(unique, counts)))\n",
    "    # print(y_pred.count(0), y_test.count(0))\n",
    "\n",
    "    \n",
    "    # print(\" Classification accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\" Micro F1 score: \", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\" Macro F1 score: \", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\" Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "    target_names = ['comment', 'support', 'deny', 'query']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    \n",
    "def class_decode(vec):\n",
    "    np_vec = np.array(vec)\n",
    "    return np.argmax(np_vec)\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size_reply,embedding_length_nn))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if word in glove_embedding:\n",
    "        embedding_value = glove_embedding[word]\n",
    "    else:\n",
    "        embedding_value = None\n",
    "    if embedding_value is not None:\n",
    "        embedding_matrix[i] = embedding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8ce5fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_38 (Embedding)    (None, 100, 100)          402100    \n",
      "                                                                 \n",
      " bidirectional_37 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 563,704\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 402,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 12s 92ms/step - loss: 0.9273 - categorical_accuracy: 0.6641 - val_loss: 0.9128 - val_categorical_accuracy: 0.6423\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.8194 - categorical_accuracy: 0.7015 - val_loss: 0.8927 - val_categorical_accuracy: 0.6584\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.7940 - categorical_accuracy: 0.7084 - val_loss: 0.9024 - val_categorical_accuracy: 0.6544\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 9s 84ms/step - loss: 0.7753 - categorical_accuracy: 0.7120 - val_loss: 0.9094 - val_categorical_accuracy: 0.6634\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7554 - categorical_accuracy: 0.7168 - val_loss: 0.9041 - val_categorical_accuracy: 0.6652\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7292 - categorical_accuracy: 0.7272 - val_loss: 0.9178 - val_categorical_accuracy: 0.6620\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7071 - categorical_accuracy: 0.7380 - val_loss: 0.9249 - val_categorical_accuracy: 0.6665\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.6840 - categorical_accuracy: 0.7446 - val_loss: 0.9599 - val_categorical_accuracy: 0.6679\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.6626 - categorical_accuracy: 0.7557 - val_loss: 0.9706 - val_categorical_accuracy: 0.6692\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 9s 84ms/step - loss: 0.6436 - categorical_accuracy: 0.7596 - val_loss: 0.9932 - val_categorical_accuracy: 0.6674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7b113ccd0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# model.add(Embedding(vocab_size, 100, input_length=100, trainable=False))\n",
    "\n",
    "# Glove embeddings\n",
    "model.add(Embedding(vocab_size_reply,100,weights = [embedding_matrix],input_length=embedding_length_nn,trainable = False))\n",
    "\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train_reply, y_train_reply, validation_split=0.4, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6c7a8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 19ms/step\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.8151 - categorical_accuracy: 0.7392\n",
      "Pred: {0: 1016, 1: 5, 2: 1, 3: 44}\n",
      "Test: {0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Micro F1 score:  0.7392120075046904\n",
      " Macro F1 score:  0.34922584160457104\n",
      " Confusion matrix: \n",
      " [[760   1   1   9]\n",
      " [137   2   0   8]\n",
      " [ 89   2   0   1]\n",
      " [ 30   0   0  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.75      0.99      0.85       771\n",
      "     support       0.40      0.01      0.03       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.59      0.46      0.52        56\n",
      "\n",
      "    accuracy                           0.74      1066\n",
      "   macro avg       0.43      0.37      0.35      1066\n",
      "weighted avg       0.63      0.74      0.65      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_reply)\n",
    "\n",
    "model.evaluate(x=X_test_reply, y=y_test_reply)\n",
    "\n",
    "y_predicted_class = [class_decode(i) for i in y_predicted]\n",
    "y_test_class = [class_decode(i) for i in y_test_reply]\n",
    "\n",
    "result_nn(y_predicted_class, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "70476f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, 100, 100)          402100    \n",
      "                                                                 \n",
      " bidirectional_38 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 563,704\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 402,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 11s 86ms/step - loss: 0.9688 - categorical_accuracy: 0.6763 - val_loss: 1.0487 - val_categorical_accuracy: 0.6338\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.9053 - categorical_accuracy: 0.6781 - val_loss: 0.9833 - val_categorical_accuracy: 0.6333\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.8520 - categorical_accuracy: 0.6853 - val_loss: 0.9874 - val_categorical_accuracy: 0.6261\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.8250 - categorical_accuracy: 0.6892 - val_loss: 0.9817 - val_categorical_accuracy: 0.6329\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.8065 - categorical_accuracy: 0.6982 - val_loss: 0.9765 - val_categorical_accuracy: 0.6315\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7877 - categorical_accuracy: 0.7069 - val_loss: 1.0008 - val_categorical_accuracy: 0.6239\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7723 - categorical_accuracy: 0.7147 - val_loss: 1.0045 - val_categorical_accuracy: 0.6270\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 9s 85ms/step - loss: 0.7530 - categorical_accuracy: 0.7231 - val_loss: 1.0223 - val_categorical_accuracy: 0.6284\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.7487 - categorical_accuracy: 0.7135 - val_loss: 1.0174 - val_categorical_accuracy: 0.6131\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 9s 83ms/step - loss: 0.7313 - categorical_accuracy: 0.7213 - val_loss: 1.0138 - val_categorical_accuracy: 0.6297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7b5d87220>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# model.add(Embedding(vocab_size, 100, input_length=100, trainable=False))\n",
    "\n",
    "# Glove embeddings\n",
    "model.add(Embedding(vocab_size_reply,100,weights = [embedding_matrix],input_length=embedding_length_nn,trainable = False))\n",
    "\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train_both, y_train_reply, validation_split=0.4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0e64213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 18ms/step\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.8702 - categorical_accuracy: 0.7223\n",
      "Pred: {0: 1007, 1: 6, 3: 53}\n",
      "Test: {0: 771, 1: 147, 2: 92, 3: 56}\n",
      " Micro F1 score:  0.7223264540337712\n",
      " Macro F1 score:  0.31029535029114347\n",
      " Confusion matrix: \n",
      " [[747   2   0  22]\n",
      " [136   4   0   7]\n",
      " [ 87   0   0   5]\n",
      " [ 37   0   0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     comment       0.74      0.97      0.84       771\n",
      "     support       0.67      0.03      0.05       147\n",
      "        deny       0.00      0.00      0.00        92\n",
      "       query       0.36      0.34      0.35        56\n",
      "\n",
      "    accuracy                           0.72      1066\n",
      "   macro avg       0.44      0.33      0.31      1066\n",
      "weighted avg       0.65      0.72      0.63      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_both)\n",
    "\n",
    "model.evaluate(x=X_test_both, y=y_test_reply)\n",
    "\n",
    "y_predicted_class = [class_decode(i) for i in y_predicted]\n",
    "y_test_class = [class_decode(i) for i in y_test_reply]\n",
    "\n",
    "result_nn(y_predicted_class, y_test_class)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
